{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task 1 XOR gate with Sigmoid Activation and Squared Error Loss.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPp0pS/1TgpD5aumsJ9vXS+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgGB8nZTdT4k","executionInfo":{"status":"ok","timestamp":1615027225851,"user_tz":-240,"elapsed":36642,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"cbd4acc7-335a-44bb-d86e-80545e509be8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88mvOF6BcuaO","executionInfo":{"status":"ok","timestamp":1615027239275,"user_tz":-240,"elapsed":1317,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"bc5eb0be-769c-4936-966b-f450f62a824b"},"source":["!ls \"drive/MyDrive/COSC 606 Machine learning/Homework 2/Notebooks/\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["'Task 1 OR gate with Softmax activation and Crossentropy loss.ipynb'\n","'Task 1 XOR gate with Sigmoid Activation and Squared Error Loss.ipynb'\n","'Task 1 XOR gate with Softmax activation and Crossentropy loss.ipynb'\n","'Task 2 work on MNIST data V1.ipynb'\n","'Task 3.1 Work on MNIST data V2.ipynb'\n","'Task 3.2 Work on MNIST data V3.ipynb'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cd85O1UZcx2B","executionInfo":{"status":"ok","timestamp":1614933698212,"user_tz":-240,"elapsed":1167,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"0697c420-eb47-46d6-d3e9-d77319c1f9f2"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kE1_iYnqctjM","executionInfo":{"status":"ok","timestamp":1614933698680,"user_tz":-240,"elapsed":1625,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"ead7cb9e-5de2-4552-880e-1bca63e35285"},"source":["import os\n","os.chdir('drive/MyDrive/COSC 606 Machine learning/Homework 2/Notebooks/')\n","!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/COSC 606 Machine learning/Homework 2/Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NiWAabRXrkQD"},"source":["import numpy as np  # import numpy library"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GwWTifgfiVDC"},"source":["def initialize_parameters(n_in, n_out, ini_type='plain'):\n","    \"\"\"\n","    Function to initialize some form of random weights and Zero biases\n","    Args:\n","        n_in: size of input layer\n","        n_out: size of output/number of neurons\n","        ini_type: set initialization type for weights\n","    Returns:\n","        params: a dictionary containing W and b\n","    \"\"\"\n","\n","    params = dict()  # initialize empty dictionary of neural net parameters W and b\n","\n","    if ini_type == 'plain':\n","        params['W'] = np.random.randn(n_out, n_in) *0.01  # set weights 'W' to small random gaussian\n","    elif ini_type == 'xavier':\n","        params['W'] = np.random.randn(n_out, n_in) / (np.sqrt(n_in))  # set variance of W to 1/n\n","    elif ini_type == 'he':\n","        # Good when ReLU used in hidden layers\n","        params['W'] = np.random.randn(n_out, n_in) * np.sqrt(2/n_in)  # set variance of W to 2/n\n","\n","    params['b'] = np.zeros((n_out, 1))    # set bias 'b' to zeros\n","\n","    return params"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"db3i3wJHasXB"},"source":["class LinearLayer:\n","    \"\"\"\n","        This Class implements all functions to be executed by a linear layer\n","        in a computational graph\n","        Args:\n","            input_shape: input shape of Data/Activations\n","            n_out: number of neurons in layer\n","            ini_type: initialization type for weight parameters, default is \"plain\"\n","                      Opitons are: plain, xavier and he\n","        Methods:\n","            forward(A_prev)\n","            backward(upstream_grad)\n","            update_params(learning_rate)\n","    \"\"\"\n","\n","    def __init__(self, input_shape, n_out, ini_type=\"plain\"):\n","        \"\"\"\n","        The constructor of the LinearLayer takes the following parameters\n","        Args:\n","            input_shape: input shape of Data/Activations\n","            n_out: number of neurons in layer\n","            ini_type: initialization type for weight parameters, default is \"plain\"\n","        \"\"\"\n","\n","        self.m = input_shape[1]  # number of examples in training data\n","        # `params` store weights and bias in a python dictionary\n","        self.params = initialize_parameters(input_shape[0], n_out, ini_type)  # initialize weights and bias\n","        self.Z = np.zeros((self.params['W'].shape[0], input_shape[1]))  # create space for resultant Z output\n","\n","    def forward(self, A_prev):\n","        \"\"\"\n","        This function performs the forwards propagation using activations from previous layer\n","        Args:\n","            A_prev:  Activations/Input Data coming into the layer from previous layer\n","        \"\"\"\n","\n","        self.A_prev = A_prev  # store the Activations/Training Data coming in\n","        self.Z = np.dot(self.params['W'], self.A_prev) + self.params['b']  # compute the linear function\n","\n","    def backward(self, upstream_grad):\n","        \"\"\"\n","        This function performs the back propagation using upstream gradients\n","        Args:\n","            upstream_grad: gradient coming in from the upper layer to couple with local gradient\n","        \"\"\"\n","\n","        # derivative of Cost w.r.t W\n","        self.dW = np.dot(upstream_grad, self.A_prev.T)\n","\n","        # derivative of Cost w.r.t b, sum across rows\n","        self.db = np.sum(upstream_grad, axis=1, keepdims=True)\n","\n","        # derivative of Cost w.r.t A_prev\n","        self.dA_prev = np.dot(self.params['W'].T, upstream_grad)\n","\n","    def update_params(self, learning_rate=0.1):\n","        \"\"\"\n","        This function performs the gradient descent update\n","        Args:\n","            learning_rate: learning rate hyper-param for gradient descent, default 0.1\n","        \"\"\"\n","\n","        self.params['W'] = self.params['W'] - learning_rate * self.dW  # update weights\n","        self.params['b'] = self.params['b'] - learning_rate * self.db  # update bias(es)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XV7V-iCgbb26"},"source":["class SigmoidLayer:\n","    \"\"\"\n","    This file implements activation layers\n","    inline with a computational graph model\n","    Args:\n","        shape: shape of input to the layer\n","    Methods:\n","        forward(Z)\n","        backward(upstream_grad)\n","    \"\"\"\n","\n","    def __init__(self, shape):\n","        \"\"\"\n","        The consturctor of the sigmoid/logistic activation layer takes in the following arguments\n","        Args:\n","            shape: shape of input to the layer\n","        \"\"\"\n","        self.A = np.zeros(shape)  # create space for the resultant activations\n","\n","    def forward(self, Z):\n","        \"\"\"\n","        This function performs the forwards propagation step through the activation function\n","        Args:\n","            Z: input from previous (linear) layer\n","        \"\"\"\n","        self.A = 1 / (1 + np.exp(-Z))  # compute activations\n","\n","    def backward(self, upstream_grad):\n","        \"\"\"\n","        This function performs the  back propagation step through the activation function\n","        Local gradient => derivative of sigmoid => A*(1-A)\n","        Args:\n","            upstream_grad: gradient coming into this layer from the layer above\n","        \"\"\"\n","        # couple upstream gradient with local gradient, the result will be sent back to the Linear layer\n","        self.dZ = upstream_grad * self.A*(1-self.A)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhkew_nSb6MJ"},"source":["def compute_cost(Y, Y_hat):\n","    \"\"\"\n","    This function computes and returns the Cost and its derivative.\n","    The is function uses the Squared Error Cost function -> (1/2m)*sum(Y - Y_hat)^.2\n","    Args:\n","        Y: labels of data\n","        Y_hat: Predictions(activations) from a last layer, the output layer\n","    Returns:\n","        cost: The Squared Error Cost result\n","        dY_hat: gradient of Cost w.r.t the Y_hat\n","    \"\"\"\n","    m = Y.shape[1]\n","\n","    cost = (1 / (2 * m)) * np.sum(np.square(Y - Y_hat))\n","    cost = np.squeeze(cost)  # remove extraneous dimensions to give just a scalar\n","\n","    dY_hat = -1 / m * (Y - Y_hat)  # derivative of the squared error cost function\n","\n","    return cost, dY_hat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voNFwm_6fH-2","executionInfo":{"status":"ok","timestamp":1614933698687,"user_tz":-240,"elapsed":1572,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"f41f0f08-ccb5-4205-be7a-cda52d06adc6"},"source":["# This is our XOR gate data \n","X = np.array([\n","    [0, 0],\n","    [0, 1],\n","    [1, 0],\n","    [1, 1]\n","])\n","\n","Y = np.array([\n","    [0],\n","    [1],\n","    [1],\n","    [0]\n","])\n","print(X.shape)\n","print(Y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4, 2)\n","(4, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9EnA6nelfJ5w","executionInfo":{"status":"ok","timestamp":1614933698688,"user_tz":-240,"elapsed":1563,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"783cd263-0dcb-4e85-e1c8-7df03e7bc3a8"},"source":["# Setting up training data\n","X_train = X.T\n","Y_train = Y.T\n","print(X_train.shape)\n","print(Y_train.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2, 4)\n","(1, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d1qwxf3Fb-_A"},"source":["# define training constants\n","learning_rate = 1\n","number_of_epochs = 5000\n","\n","np.random.seed(48) # set seed value so that the results are reproduceable\n","                  # (weights will now be initailzaed to the same pseudo-random numbers, each time)\n","\n","\n","# Our network architecture has the shape: \n","#                   (input)--> [Linear->Sigmoid] -> [Linear->Sigmoid] -->(output)  \n","\n","#------ LAYER-1 ----- define hidden layer that takes in training data \n","Z1 = LinearLayer(input_shape=X_train.shape, n_out=3, ini_type='xavier')\n","A1 = SigmoidLayer(Z1.Z.shape)\n","\n","#------ LAYER-2 ----- define output layer that take is values from hidden layer\n","Z2= LinearLayer(input_shape=A1.A.shape, n_out=1, ini_type='xavier')\n","A2= SigmoidLayer(Z2.Z.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSUW5phkfiHg","executionInfo":{"status":"ok","timestamp":1614933699401,"user_tz":-240,"elapsed":2259,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"ff395414-36b4-4ae4-fc78-60a882034070"},"source":["costs = [] # initially empty list, this will store all the costs after a certian number of epochs\n","\n","# Start training\n","for epoch in range(number_of_epochs):\n","    \n","    # ------------------------- forward-prop -------------------------\n","    Z1.forward(X_train)\n","    A1.forward(Z1.Z)\n","    \n","    Z2.forward(A1.A)\n","    A2.forward(Z2.Z)\n","    \n","    # ---------------------- Compute Cost ----------------------------\n","    cost, dA2 = compute_cost(Y=Y_train, Y_hat=A2.A)\n","    \n","    # print and store Costs every 100 iterations.\n","    if (epoch % 100) == 0:\n","        print(\"Cost at epoch#{}: {}\".format(epoch, cost))\n","        costs.append(cost)\n","    \n","    # ------------------------- back-prop ----------------------------\n","    A2.backward(dA2)\n","    Z2.backward(A2.dZ)\n","    \n","    A1.backward(Z2.dA_prev)\n","    Z1.backward(A1.dZ)\n","    \n","    # ----------------------- Update weights and bias ----------------\n","    Z2.update_params(learning_rate=learning_rate)\n","    Z1.update_params(learning_rate=learning_rate)\n","\n","# See what the final weights and bias are training    \n","# print(Z1.params)\n","# print(Z2.params)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cost at epoch#0: 0.12926510193084198\n","Cost at epoch#100: 0.12345825692804888\n","Cost at epoch#200: 0.12066966113381941\n","Cost at epoch#300: 0.11668036021258062\n","Cost at epoch#400: 0.11130833351272905\n","Cost at epoch#500: 0.10488049601356227\n","Cost at epoch#600: 0.09838889588798089\n","Cost at epoch#700: 0.09243739122926581\n","Cost at epoch#800: 0.08674109898244503\n","Cost at epoch#900: 0.08036338003614363\n","Cost at epoch#1000: 0.07188849409230211\n","Cost at epoch#1100: 0.06026682287648238\n","Cost at epoch#1200: 0.04667277906214774\n","Cost at epoch#1300: 0.034031803169728744\n","Cost at epoch#1400: 0.02442089220979804\n","Cost at epoch#1500: 0.017883350379483135\n","Cost at epoch#1600: 0.013556791347344183\n","Cost at epoch#1700: 0.010645079603116687\n","Cost at epoch#1800: 0.00862108131339213\n","Cost at epoch#1900: 0.007164447639006826\n","Cost at epoch#2000: 0.006081828121979098\n","Cost at epoch#2100: 0.005254042338109353\n","Cost at epoch#2200: 0.004605397868807181\n","Cost at epoch#2300: 0.0040862927529649404\n","Cost at epoch#2400: 0.003663237628268156\n","Cost at epoch#2500: 0.0033129939134783626\n","Cost at epoch#2600: 0.0030190324028718917\n","Cost at epoch#2700: 0.0027693324145448756\n","Cost at epoch#2800: 0.002554976583459256\n","Cost at epoch#2900: 0.0023692307657675413\n","Cost at epoch#3000: 0.002206927429923999\n","Cost at epoch#3100: 0.002064043543916351\n","Cost at epoch#3200: 0.001937405929254176\n","Cost at epoch#3300: 0.0018244818957577195\n","Cost at epoch#3400: 0.0017232280289235047\n","Cost at epoch#3500: 0.0016319793324127336\n","Cost at epoch#3600: 0.0015493668312470718\n","Cost at epoch#3700: 0.0014742555487292142\n","Cost at epoch#3800: 0.001405697270526658\n","Cost at epoch#3900: 0.0013428941792192049\n","Cost at epoch#4000: 0.001285170575365443\n","Cost at epoch#4100: 0.0012319506808326393\n","Cost at epoch#4200: 0.0011827410641545035\n","Cost at epoch#4300: 0.0011371166121251185\n","Cost at epoch#4400: 0.0010947092467665257\n","Cost at epoch#4500: 0.001055198785625857\n","Cost at epoch#4600: 0.0010183054886511822\n","Cost at epoch#4700: 0.0009837839421244113\n","Cost at epoch#4800: 0.0009514180100050967\n","Cost at epoch#4900: 0.0009210166430616625\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0cUqHetLi79q"},"source":["def predict(X, Y, Zs, As):\n","    m = X.shape[1]\n","    n = len(Zs)  # number of layers in the neural network\n","    p = np.zeros((1, m))\n","\n","    # Forward propagation\n","    Zs[0].forward(X)\n","    As[0].forward(Zs[0].Z)\n","    for i in range(1, n):\n","        Zs[i].forward(As[i-1].A)\n","        As[i].forward(Zs[i].Z)\n","    probas = As[n-1].A\n","\n","    # convert probas to 0/1 predictions\n","    for i in range(0, probas.shape[1]):\n","        if probas[0, i] > 0.5:  # 0.5 is threshold\n","            p[0, i] = 1\n","        else:\n","            p[0, i] = 0\n","\n","    accuracy = np.sum((p == Y) / m)\n","\n","    return p, probas, accuracy*100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iX-ArkGnfqow","executionInfo":{"status":"ok","timestamp":1614933699404,"user_tz":-240,"elapsed":2238,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"ac7db7c9-9621-4ebd-9ec8-d466758a758a"},"source":["predicted_outputs, _, accuracy = predict(X=X_train, Y=Y_train, Zs=[Z1, Z2], As=[A1, A2])\n","\n","print(\"The predicted outputs:\\n {}\".format(predicted_outputs))\n","print(\"The accuracy of the model is: {}%\".format(accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The predicted outputs:\n"," [[0. 1. 1. 0.]]\n","The accuracy of the model is: 100.0%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jcupa4f4jEBI"},"source":["def plot_learning_curve(costs, learning_rate, total_epochs, save=False):\n","    \"\"\"\n","    This function plots the Learning Curve of the model\n","\n","    Args:\n","        costs: list of costs recorded during training\n","        learning_rate: the learning rate during training\n","        total_epochs: number of epochs the model was trained for\n","        save: bool flag to save the image or not. Default False\n","    \"\"\"\n","    # plot the cost\n","    import matplotlib.pyplot as plt\n","    plt.figure()\n","\n","    steps = int(total_epochs / len(costs))  # the steps at with costs were recorded\n","    plt.ylabel('Cost')\n","    plt.xlabel('Iterations ')\n","    plt.title(\"Learning rate =\" + str(learning_rate))\n","    plt.plot(np.squeeze(costs))\n","    locs, labels = plt.xticks()\n","    plt.xticks(locs[1:-1], tuple(np.array(locs[1:-1], dtype='int')*steps))  # change x labels of the plot\n","    plt.xticks()\n","    if save:\n","        plt.savefig('Cost_Curve.png', bbox_inches='tight')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"Am11hNKEgFQd","executionInfo":{"status":"ok","timestamp":1614933699928,"user_tz":-240,"elapsed":2739,"user":{"displayName":"Adarsh Ghimire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64","userId":"03649801403498526934"}},"outputId":"3fa96ec1-74e4-4d89-a147-94e94e111227"},"source":["plot_learning_curve(costs=costs, learning_rate=learning_rate, total_epochs=number_of_epochs)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}